defaults:
  - override hydra/launcher: local.yaml

##########
# naming
##########
name: '${env.name}-${model.name}-${suffix}'
suffix: 'default'
model:
  name: 'multi'
  use_local_conv: false
  use_grid_attn: false
  field_attn: false
  stateful: false
  num_film: 5
  demb: 100
  drnn: 200
  drep: 400

env:
  name: 'silg:rtfm_train_s1-v0'
  time_penalty: -0.02
project: 'wrangl-example-silg-rl'
peer: 0

##########
# launcher
##########
hydra:
  job:
    name: '${name}'
    env_set:
      OMP_NUM_THREADS: '1'
      RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE: '1'
  run:
    dir: '${oc.env:PWD}'
  sweep:
    dir: '${savedir}/sweep'

##########
# wandb
##########
wandb:  # wandb settings
  enable: false
  project: '${project}'
  name: '${name}'
  entity: '${oc.env:USER}'

##########
# training
##########
savedir: '${oc.env:PWD}/saves/${name}'
localdir: "${savedir}/peers/${peer}"
local_name: "${name}-${peer}"
ckpt_path: '${savedir}/latest.ckpt'
debug: false
max_steps: 1_000_000_000
autoresume: false

device: 'cuda:0'
strategy: null
actor_batch_size: 256
baseline_cost: 0.5
batch_size: 128
connect: '100.97.69.72:4431'
discounting: 0.99
entropy_cost: 0.005
grad_clip_norm: 40
log_fmt: "[%(levelname)s:${name} %(module)s:%(lineno)d %(asctime)s] %(message)s"
log_interval: 10
checkpoint_interval: 600
num_actor_batches: 2
num_actor_cpus: 10
optimizer:
  learning_rate: 0.0005
  alpha: 0.99
  momentum: 0
  epsilon: 0.01  # PyTorch default: 1e-08
unroll_length: 20
virtual_batch_size: 128
reward_clip: 1.0
warmup: 0
